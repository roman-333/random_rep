{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAT 207 Group Lab Assignment 13 - [10 total points]\n",
    "\n",
    "## Measuring Model Performance & Model Searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Lab Grading</u>:\n",
    "\n",
    "Should we grade your submission?  If not, write the netID of the submission to be graded.  (Note: We will only grade one assignment per group, and we'll pick the first one that says we should grade that submission.  We will assign the same grade to all team members.)\n",
    "\n",
    "*For example*, you might respond: **grade this submission** or **my submission is under netID jdeeke**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grade this submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you said **my submission is under netID** above, we will not read any more of your lab submission.\n",
    "\n",
    "If you said **grade this submission** above, who worked with you on this submission?  Write both their **names** and **netIDs**.  \n",
    "\n",
    "Also, discuss and record if you've ever been on a cruise before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "None of us have been on a cruise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Purpose</u>:\n",
    "You should work in groups of 2-3 on this report (not working in groups without permission will result in a point deduction). The purpose of this group lab assignment is to assess model fit and overfitting through model searching.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Roles\n",
    "\n",
    "Suggested and specified roles are provided below: \n",
    "\n",
    "#### Groups of 2\n",
    "\n",
    "* **Driver**: This student will type the report.  While typing the report, you may be the one who is selecting the functions to apply to the data.\n",
    "* **Navigator**: This student will guide the process of answering the question.  Specific ways to help may include: outlining the general steps needed to solve a question (providing the overview), locating examples within the course notes, and reviewing each line of code as it is typed.\n",
    "\n",
    "#### Groups of 3\n",
    "\n",
    "* **Driver**: This student will type the report.  They may also be the one to select the functions to apply to the data.\n",
    "* **Navigator**: This student will guide the process of answering the question.  They may select the general approach to answering the question and/or a few steps to be completed along the way. \n",
    "* **Communicator**: This student will review the report (as it is typed) to ensure that it is clear and concise.  This student may also locate relevant examples within the course notes that may help complete the assignment.\n",
    "\n",
    "<hr>\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this\n",
    "import pandas as pd                    # imports pandas and calls the imported version 'pd'\n",
    "import matplotlib.pyplot as plt        # imports the package and calls it 'plt'\n",
    "import seaborn as sns                  # imports the seaborn package with the imported name 'sns'\n",
    "sns.set()  \n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study: Crew Size on Cruise Ships\n",
    "\n",
    "We will look at data collected about the size of a crew (in hundreds) on cruise ships.  In particular, we would like to be able to predict the size of the crew needed for a cruise ship from other characteristics about that ship.  The original data can be found here: https://github.com/bot13956/ML_Model_for_Predicting_Ships_Crew_Size/blob/master/cruise_ship_info.csv.\n",
    "\n",
    "For this case study, we will consider the following variables:\n",
    "\n",
    "- **Age**: the age of the ship (years)\n",
    "- **Tonnage**: the amount of water the ship displaces\n",
    "- **passengers**: the max number of passengers the ship can hold (in 100s)\n",
    "- **length**: the length of the ship (in hundrds of feet)\n",
    "- **cabins**: the number of cabins (in 100s)\n",
    "- **passenger_density**: a space ratio for how much space is on board per passenger\n",
    "- **crew**: the number of crew members on the ship (in 100s)\n",
    "\n",
    "The code cell below will read in the data for you and create a test and training set.  Be sure to run the cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cruise_ship_info.csv')\n",
    "df_train, df_test = train_test_split(df, test_size = 0.2, random_state = 425)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. [4 points] Searching for a Good Model\n",
    "\n",
    "**a)** Perform forward selection using the adjusted $R^2$ ($R^2_\\text{adj}$) as your metric on your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>crew</td>       <th>  R-squared:         </th> <td>  -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>     nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 23 Apr 2025</td> <th>  Prob (F-statistic):</th>  <td>   nan</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:50:33</td>     <th>  Log-Likelihood:    </th> <td> -338.48</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   126</td>      <th>  AIC:               </th> <td>   679.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   125</td>      <th>  BIC:               </th> <td>   681.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     0</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    7.8694</td> <td>    0.318</td> <td>   24.772</td> <td> 0.000</td> <td>    7.241</td> <td>    8.498</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 5.753</td> <th>  Durbin-Watson:     </th> <td>   1.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.056</td> <th>  Jarque-Bera (JB):  </th> <td>   6.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.309</td> <th>  Prob(JB):          </th> <td>  0.0443</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.898</td> <th>  Cond. No.          </th> <td>    1.00</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       crew       & \\textbf{  R-squared:         } &    -0.000   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &    -0.000   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &       nan   \\\\\n",
       "\\textbf{Date:}             & Wed, 23 Apr 2025 & \\textbf{  Prob (F-statistic):} &      nan    \\\\\n",
       "\\textbf{Time:}             &     15:50:33     & \\textbf{  Log-Likelihood:    } &   -338.48   \\\\\n",
       "\\textbf{No. Observations:} &         126      & \\textbf{  AIC:               } &     679.0   \\\\\n",
       "\\textbf{Df Residuals:}     &         125      & \\textbf{  BIC:               } &     681.8   \\\\\n",
       "\\textbf{Df Model:}         &           0      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &       7.8694  &        0.318     &    24.772  &         0.000        &        7.241    &        8.498     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  5.753 & \\textbf{  Durbin-Watson:     } &    1.985  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.056 & \\textbf{  Jarque-Bera (JB):  } &    6.234  \\\\\n",
       "\\textbf{Skew:}          &  0.309 & \\textbf{  Prob(JB):          } &   0.0443  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.898 & \\textbf{  Cond. No.          } &     1.00  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   crew   R-squared:                      -0.000\n",
       "Model:                            OLS   Adj. R-squared:                 -0.000\n",
       "Method:                 Least Squares   F-statistic:                       nan\n",
       "Date:                Wed, 23 Apr 2025   Prob (F-statistic):                nan\n",
       "Time:                        15:50:33   Log-Likelihood:                -338.48\n",
       "No. Observations:                 126   AIC:                             679.0\n",
       "Df Residuals:                     125   BIC:                             681.8\n",
       "Df Model:                           0                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      7.8694      0.318     24.772      0.000       7.241       8.498\n",
       "==============================================================================\n",
       "Omnibus:                        5.753   Durbin-Watson:                   1.985\n",
       "Prob(Omnibus):                  0.056   Jarque-Bera (JB):                6.234\n",
       "Skew:                           0.309   Prob(JB):                       0.0443\n",
       "Kurtosis:                       3.898   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_model = smf.ols('crew ~ 1', data=df_train).fit()\n",
    "current_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: Adjusted R² = 0.34191\n",
      "Tonnage: Adjusted R² = 0.86783\n",
      "passengers: Adjusted R² = 0.85316\n",
      "length: Adjusted R² = 0.79757\n",
      "cabins: Adjusted R² = 0.92011\n",
      "passenger_density: Adjusted R² = -0.00258\n"
     ]
    }
   ],
   "source": [
    "variables = ['Age', 'Tonnage', 'passengers', 'length', 'cabins', 'passenger_density']\n",
    "\n",
    "for var in variables:\n",
    "    formula = f'crew ~ {var}'\n",
    "    model = smf.ols(formula, data=df_train).fit()\n",
    "    print(f'{var}: Adjusted R² = {model.rsquared_adj:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: Adjusted R² = 0.92075\n",
      "Tonnage: Adjusted R² = 0.92331\n",
      "passengers: Adjusted R² = 0.92226\n",
      "length: Adjusted R² = 0.92712\n",
      "passenger_density: Adjusted R² = 0.92534\n"
     ]
    }
   ],
   "source": [
    "current_model = smf.ols('crew ~ cabins', data=df_train).fit()\n",
    "variables = ['Age', 'Tonnage', 'passengers', 'length', 'passenger_density']\n",
    "\n",
    "for var in variables:\n",
    "    formula = f'crew ~ cabins + {var}'\n",
    "    model = smf.ols(formula, data=df_train).fit()\n",
    "    print(f'{var}: Adjusted R² = {model.rsquared_adj:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: Adjusted R² = 0.92694\n",
      "Tonnage: Adjusted R² = 0.92685\n",
      "passengers: Adjusted R² = 0.93101\n",
      "passenger_density: Adjusted R² = 0.92923\n"
     ]
    }
   ],
   "source": [
    "current_model = smf.ols('crew ~ cabins + length', data=df_train).fit()\n",
    "variables = ['Age', 'Tonnage', 'passengers', 'passenger_density']\n",
    "\n",
    "for var in variables:\n",
    "    formula = f'crew ~ cabins + length + {var}'\n",
    "    model = smf.ols(formula, data=df_train).fit()\n",
    "    print(f'{var}: Adjusted R² = {model.rsquared_adj:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: Adjusted R² = 0.93123\n",
      "Tonnage: Adjusted R² = 0.93213\n",
      "passenger_density: Adjusted R² = 0.93150\n"
     ]
    }
   ],
   "source": [
    "current_model = smf.ols('crew ~ cabins + length + passengers', data=df_train).fit()\n",
    "variables = ['Age', 'Tonnage', 'passenger_density']\n",
    "\n",
    "for var in variables:\n",
    "    formula = f'crew ~ cabins + length + passengers + {var}'\n",
    "    model = smf.ols(formula, data=df_train).fit()\n",
    "    print(f'{var}: Adjusted R² = {model.rsquared_adj:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: Adjusted R² = 0.93175\n",
      "passenger_density: Adjusted R² = 0.93159\n"
     ]
    }
   ],
   "source": [
    "current_model = smf.ols('crew ~ cabins + length + passengers + Tonnage', data=df_train).fit()\n",
    "variables = ['Age', 'passenger_density']\n",
    "\n",
    "for var in variables:\n",
    "    formula = f'crew ~ cabins + length + passengers + Tonnage + {var}'\n",
    "    model = smf.ols(formula, data=df_train).fit()\n",
    "    print(f'{var}: Adjusted R² = {model.rsquared_adj:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>crew</td>       <th>  R-squared:         </th> <td>   0.934</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.932</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   430.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 23 Apr 2025</td> <th>  Prob (F-statistic):</th> <td>1.67e-70</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:50:34</td>     <th>  Log-Likelihood:    </th> <td> -166.95</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   126</td>      <th>  AIC:               </th> <td>   343.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   121</td>      <th>  BIC:               </th> <td>   358.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>   -0.5085</td> <td>    0.630</td> <td>   -0.807</td> <td> 0.421</td> <td>   -1.756</td> <td>    0.740</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cabins</th>     <td>    0.7955</td> <td>    0.089</td> <td>    8.974</td> <td> 0.000</td> <td>    0.620</td> <td>    0.971</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>length</th>     <td>    0.3137</td> <td>    0.120</td> <td>    2.607</td> <td> 0.010</td> <td>    0.075</td> <td>    0.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>passengers</th> <td>   -0.1306</td> <td>    0.040</td> <td>   -3.237</td> <td> 0.002</td> <td>   -0.211</td> <td>   -0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tonnage</th>    <td>    0.0152</td> <td>    0.009</td> <td>    1.735</td> <td> 0.085</td> <td>   -0.002</td> <td>    0.032</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>132.153</td> <th>  Durbin-Watson:     </th> <td>   2.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3664.597</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 3.452</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>28.502</td>  <th>  Cond. No.          </th> <td>    664.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       crew       & \\textbf{  R-squared:         } &     0.934   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.932   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     430.2   \\\\\n",
       "\\textbf{Date:}             & Wed, 23 Apr 2025 & \\textbf{  Prob (F-statistic):} &  1.67e-70   \\\\\n",
       "\\textbf{Time:}             &     15:50:34     & \\textbf{  Log-Likelihood:    } &   -166.95   \\\\\n",
       "\\textbf{No. Observations:} &         126      & \\textbf{  AIC:               } &     343.9   \\\\\n",
       "\\textbf{Df Residuals:}     &         121      & \\textbf{  BIC:               } &     358.1   \\\\\n",
       "\\textbf{Df Model:}         &           4      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                    & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}  &      -0.5085  &        0.630     &    -0.807  &         0.421        &       -1.756    &        0.740     \\\\\n",
       "\\textbf{cabins}     &       0.7955  &        0.089     &     8.974  &         0.000        &        0.620    &        0.971     \\\\\n",
       "\\textbf{length}     &       0.3137  &        0.120     &     2.607  &         0.010        &        0.075    &        0.552     \\\\\n",
       "\\textbf{passengers} &      -0.1306  &        0.040     &    -3.237  &         0.002        &       -0.211    &       -0.051     \\\\\n",
       "\\textbf{Tonnage}    &       0.0152  &        0.009     &     1.735  &         0.085        &       -0.002    &        0.032     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 132.153 & \\textbf{  Durbin-Watson:     } &    2.125  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3664.597  \\\\\n",
       "\\textbf{Skew:}          &   3.452 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  28.502 & \\textbf{  Cond. No.          } &     664.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   crew   R-squared:                       0.934\n",
       "Model:                            OLS   Adj. R-squared:                  0.932\n",
       "Method:                 Least Squares   F-statistic:                     430.2\n",
       "Date:                Wed, 23 Apr 2025   Prob (F-statistic):           1.67e-70\n",
       "Time:                        15:50:34   Log-Likelihood:                -166.95\n",
       "No. Observations:                 126   AIC:                             343.9\n",
       "Df Residuals:                     121   BIC:                             358.1\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -0.5085      0.630     -0.807      0.421      -1.756       0.740\n",
       "cabins         0.7955      0.089      8.974      0.000       0.620       0.971\n",
       "length         0.3137      0.120      2.607      0.010       0.075       0.552\n",
       "passengers    -0.1306      0.040     -3.237      0.002      -0.211      -0.051\n",
       "Tonnage        0.0152      0.009      1.735      0.085      -0.002       0.032\n",
       "==============================================================================\n",
       "Omnibus:                      132.153   Durbin-Watson:                   2.125\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3664.597\n",
       "Skew:                           3.452   Prob(JB):                         0.00\n",
       "Kurtosis:                      28.502   Cond. No.                         664.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_model = smf.ols('crew ~ cabins + length + passengers + Tonnage', data=df_train).fit()\n",
    "forward_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Briefly summarize the results of this selection process.  Be sure to answer:\n",
    "- What was your starting model?\n",
    "- What was the most important initial variable to add to the model?\n",
    "- What was your final model?\n",
    "- What was the $R^2_\\text{adj}$ of your final model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The starting model was 'crew ~ 1', so just the intercept. The most important initial variable to add to the model was cabins. It led to the largest jump in the model's adjusted R-squared. The final model was 'crew ~ cabins + length + passengers + Tonnage' and its R-squared was 0.932."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. [2.5 points]  Check for Multicollinearity\n",
    "\n",
    "**a)** Now, check your model that you selected in Question 1 after forward selection for multicollinearity.  You may use either a visualization or summary statistics to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Variable        VIF\n",
      "0   Intercept  58.019096\n",
      "1      cabins  23.666153\n",
      "2      length   6.770778\n",
      "3  passengers  23.224946\n",
      "4     Tonnage  16.451396\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from patsy import dmatrices\n",
    "\n",
    "y, X = dmatrices('crew ~ cabins + length + passengers + Tonnage', data=df_train, return_type='dataframe')\n",
    "\n",
    "vif_df = pd.DataFrame()\n",
    "vif_df['Variable'] = X.columns\n",
    "vif_df['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "print(vif_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Based on what you see from part a, which variables (if any) would you like to remove from your model to reduce multicollinearity?  Briefly explain how you selected your variables that you wanted to remove.  Then, fit a new model to the training data using your reduced set of selected predictors.\n",
    "\n",
    "*Note*: If you are satisfied with your current model for multicollinearity, pick the least important predictor to remove from the model, and fit an updated model to the training data with your selected predictors.  Be sure to explain why you did not want to remove any variables.\n",
    "\n",
    "*Second note*: there is not a single correct answer here.  We are hoping that you make a reasonable choice based on your current understanding of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I removed cabins because it had the highest collinearity. Then I removed Tonnage because the VIFs were still over 10 in the reduced model. At that point, the collinearity under 10 for all variables so I left it at that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Variable        VIF\n",
      "0   Intercept  57.974577\n",
      "1      length   6.699548\n",
      "2  passengers  10.545761\n",
      "3     Tonnage  15.457914\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from patsy import dmatrices\n",
    "\n",
    "y, X = dmatrices('crew ~ length + passengers + Tonnage', data=df_train, return_type='dataframe')\n",
    "\n",
    "vif_df = pd.DataFrame()\n",
    "vif_df['Variable'] = X.columns\n",
    "vif_df['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "print(vif_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Variable        VIF\n",
      "0   Intercept  42.751955\n",
      "1      length   4.557747\n",
      "2  passengers   4.557747\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from patsy import dmatrices\n",
    "\n",
    "y, X = dmatrices('crew ~ length + passengers', data=df_train, return_type='dataframe')\n",
    "\n",
    "vif_df = pd.DataFrame()\n",
    "vif_df['Variable'] = X.columns\n",
    "vif_df['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "print(vif_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>crew</td>       <th>  R-squared:         </th> <td>   0.882</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   457.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 23 Apr 2025</td> <th>  Prob (F-statistic):</th> <td>1.03e-57</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:50:34</td>     <th>  Log-Likelihood:    </th> <td> -204.06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   126</td>      <th>  AIC:               </th> <td>   414.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   123</td>      <th>  BIC:               </th> <td>   422.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>   -1.9778</td> <td>    0.720</td> <td>   -2.745</td> <td> 0.007</td> <td>   -3.404</td> <td>   -0.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>length</th>     <td>    0.6997</td> <td>    0.131</td> <td>    5.322</td> <td> 0.000</td> <td>    0.439</td> <td>    0.960</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>passengers</th> <td>    0.2202</td> <td>    0.024</td> <td>    9.253</td> <td> 0.000</td> <td>    0.173</td> <td>    0.267</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>72.073</td> <th>  Durbin-Watson:     </th> <td>   1.945</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>1057.278</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.504</td> <th>  Prob(JB):          </th> <td>2.60e-230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.869</td> <th>  Cond. No.          </th> <td>    150.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       crew       & \\textbf{  R-squared:         } &     0.882   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.880   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     457.9   \\\\\n",
       "\\textbf{Date:}             & Wed, 23 Apr 2025 & \\textbf{  Prob (F-statistic):} &  1.03e-57   \\\\\n",
       "\\textbf{Time:}             &     15:50:34     & \\textbf{  Log-Likelihood:    } &   -204.06   \\\\\n",
       "\\textbf{No. Observations:} &         126      & \\textbf{  AIC:               } &     414.1   \\\\\n",
       "\\textbf{Df Residuals:}     &         123      & \\textbf{  BIC:               } &     422.6   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                    & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}  &      -1.9778  &        0.720     &    -2.745  &         0.007        &       -3.404    &       -0.552     \\\\\n",
       "\\textbf{length}     &       0.6997  &        0.131     &     5.322  &         0.000        &        0.439    &        0.960     \\\\\n",
       "\\textbf{passengers} &       0.2202  &        0.024     &     9.253  &         0.000        &        0.173    &        0.267     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 72.073 & \\textbf{  Durbin-Watson:     } &     1.945  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &  1057.278  \\\\\n",
       "\\textbf{Skew:}          &  1.504 & \\textbf{  Prob(JB):          } & 2.60e-230  \\\\\n",
       "\\textbf{Kurtosis:}      & 16.869 & \\textbf{  Cond. No.          } &      150.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   crew   R-squared:                       0.882\n",
       "Model:                            OLS   Adj. R-squared:                  0.880\n",
       "Method:                 Least Squares   F-statistic:                     457.9\n",
       "Date:                Wed, 23 Apr 2025   Prob (F-statistic):           1.03e-57\n",
       "Time:                        15:50:34   Log-Likelihood:                -204.06\n",
       "No. Observations:                 126   AIC:                             414.1\n",
       "Df Residuals:                     123   BIC:                             422.6\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -1.9778      0.720     -2.745      0.007      -3.404      -0.552\n",
       "length         0.6997      0.131      5.322      0.000       0.439       0.960\n",
       "passengers     0.2202      0.024      9.253      0.000       0.173       0.267\n",
       "==============================================================================\n",
       "Omnibus:                       72.073   Durbin-Watson:                   1.945\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1057.278\n",
       "Skew:                           1.504   Prob(JB):                    2.60e-230\n",
       "Kurtosis:                      16.869   Cond. No.                         150.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_model = smf.ols('crew ~ length + passengers', data=df_train).fit()\n",
    "reduced_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. [3.5 points] Comparing Our Two Models for Overfitting\n",
    "\n",
    "We now have two candidate models: our model from forward selection in Question 1 and our reduced model from Question 2.  In this question, we'll aim to identify which model performs better on *new* data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Calculate the RMSE for each of our two models on each of our two data sets: the training and the test set.  Be sure that you use the same original model for both calculations (that is, you don't need to re-fit a second version of your model to your test data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "y_train_actual = df_train['crew']\n",
    "y_train_pred_fwd = forward_model.predict(df_train)\n",
    "y_train_pred_reduced = reduced_model.predict(df_train)\n",
    "\n",
    "rmse_train_fwd = np.sqrt(mean_squared_error(y_train_actual, y_train_pred_fwd))\n",
    "rmse_train_reduced = np.sqrt(mean_squared_error(y_train_actual, y_train_pred_reduced))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_actual = df_test['crew']\n",
    "y_test_pred_fwd = forward_model.predict(df_test)\n",
    "y_test_pred_reduced = reduced_model.predict(df_test)\n",
    "\n",
    "rmse_test_fwd = np.sqrt(mean_squared_error(y_test_actual, y_test_pred_fwd))\n",
    "rmse_test_reduced = np.sqrt(mean_squared_error(y_test_actual, y_test_pred_reduced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward selected Model - Training RMSE: 0.910\n",
      "Forward selected Model - Testing RMSE:  1.168\n",
      "Reduced Model - Training RMSE: 1.222\n",
      "Reduced Model - Testing RMSE:  1.355\n"
     ]
    }
   ],
   "source": [
    "print(f\"Forward selected Model - Training RMSE: {rmse_train_fwd:.3f}\")\n",
    "print(f\"Forward selected Model - Testing RMSE:  {rmse_test_fwd:.3f}\")\n",
    "print(f\"Reduced Model - Training RMSE: {rmse_train_reduced:.3f}\")\n",
    "print(f\"Reduced Model - Testing RMSE:  {rmse_test_reduced:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Based on these results, which model would you prefer?  Briefly explain how you picked your preferred model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although my full model has high collinearity, it has higher accuracy on both the training and testing sets. For this reason, I would prefer the full, forward-selected model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Do your results from Question 1 (forward searching) and Question 3 (RMSE) suggest using the same model?  \n",
    "\n",
    "What characteristic of a model is prioritized by each of the metrics used in Questions 1 ($R^2_\\text{adj})$, 2 (multicollinearity), and 3 (RMSE)?  \n",
    "\n",
    "*Note:* You should have one answer for each of the three metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions 1 and 3 suggest using the full, forward selected model. R-squared prioritizes parsimoniousness, multicollinearity prioritizes stability, and RMSE prioritizes pure accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
